#     possible combinations.
# If you want to run the rarefaction multiple times filtered for each unique value in a specific column,
#     set the input 'filter_col' equal to the name of that column.
# Turn 'verbose' to FALSE if you don't want to see the output as it works.
rarefaction = function(abundance_table,
fun=richness,
species_col=T,
rand_combinations=100,
filter_col="",
verbose=TRUE){
if (filter_col != ""){
filter_unique = unique(abundance_table[[filter_col]])
filter_num = which(names(abundance_table)==filter_col)
num_unique = length(filter_unique)
n_sample = 0
for (u in filter_unique){
n_sample = max(n_sample,sum(abundance_table[[filter_col]]==u))
}
}else{
num_unique = 1
n_sample = nrow(abundance_table[,species_col])    # the number of samples in the dataset
}
output = rep(0,n_sample*num_unique)
output_95 = rep(0,n_sample*num_unique)
# loop over each unique element in the filter column if specified
for (u in 1:num_unique){
# filter the abundance table for the first element
if (filter_col != ""){
filter_abundance_table = filter_at(abundance_table,filter_num,all_vars(.==filter_unique[u]))
}else{
filter_abundance_table = abundance_table
}
filter_abundance_table = filter_abundance_table[,species_col]   # keep only the species count data
# loop from 1 to the number of samples
for (n in 1:n_sample){
n_combinations = choose(n_sample,n) # the total number of combinations of n samples
# check if the number of combinations is larger than specified
if (rand_combinations<n_combinations){
n_combinations = rand_combinations
sample_order = matrix(0,n,rand_combinations)
i = 1
while (i <= rand_combinations){ # loop over the number of combinations
sample_order[,i] = sample(n_sample,n) # random order of samples
for (j in 1:i){ # check to make sure the sample has not already been chosen
if (j != i){
if (all(sample_order[,i]-sample_order[,j] == 0)){
i = i-1
break
}
}
}
i = 1+i
}
}else{
sample_order = combn(n_sample,n) # find all possible combinations of n samples
}
temp_out = rep(0,n_combinations)
for (i in 1:n_combinations){
temp_sample = filter_abundance_table[sample_order[,i],] # use only chosen samples
temp_out[i] = fun(temp_sample) # calculate function
}
output[n + (u-1)*n_sample] = mean(temp_out)
output_95[n + (u-1)*n_sample] = 1.96*sd(temp_out)/sqrt(i) # calculate 95 confidence interval of the mean
if (verbose) print(paste(n+(u-1)*n_sample,'/',num_unique*n_sample,', Number of Samples:',n_combinations,', Value:',output[n],sep=""))
}
}
if (filter_col != ""){
return(tibble(n_samples=rep(1:n_sample,times=num_unique),
value=output,
conf_95=output_95,
filter=rep(filter_unique,each=n_sample)))
}else{
return(tibble(n_samples=1:n_sample,
value=output,
conf_95=output_95))
}
}
library(tidyverse)
amato_16s = read.table("Lab02/Amato_16S_primate_OTU_table_genus-level.txt", # open a .txt file
header = TRUE, # 1st row将被认为是header而非数据
sep = "\t") # sep = "," in .csv
setwd("D:/BIOL448J_Lab")
library(tidyverse)
amato_16s = read.table("Lab02/Amato_16S_primate_OTU_table_genus-level.txt", # open a .txt file
header = TRUE, # 1st row将被认为是header而非数据
sep = "\t") # sep = "," in .csv
run_all_diversity(amato_16s, species_col = 4: ncol(amato_16s)) # from 4th column to the end
run_all_diversity(amato_16s, species_col = 4: ncol(amato_16s)) # from 4th column to the end
library(tidyverse)
# read in abundace
amato_16s = read.table("Lab02/Amato_16S_primate_OTU_table_genus-level.txt", # open a .txt file
header = TRUE, # 1st row将被认为是header而非数据
sep = "\t") # sep = "," in .csv
seagrass_16s = read.table("Lab02/Seagrass_2015_otu_metadata_clean.txt",
header = TRUE, #
sep = "\t")
View(amato_16s) # colnames: sample_ID (1st col: taxonomy).  rownames: taxonomy
col_names = amato_16s$Taxonomy # 将taxonomy赋给col_names()（更改col名）
amato_16s = as.data.frame(t(amato_16s[,-1])) # 去掉1st col后转换col和row
names(amato_16s) = col_names # 给data的col赋值
###################################
# Biodiversity Measures Functions #
###################################
### Don't edit these.
### Read them and see if you understand what is happening.
### Either copy and paste them into your script, or jump down and
###   start writing below
### All of these functions take a matrix 'abundance_table'.
### If you only have one sample, a vector of species counts is also OK.
### This matrix is simply an array with species/OTUs/etc as columns and
###   samples as rows. Values are the number of the species found in the
###   sample. Metadata columns are not allowed for these calculation functions.
###   If you want to use them directly be sure to remove the metadata columns
###   first (e.g., data[,4:nrow(data)]). The rarefaction function below has an
###   optional inpput specifiy the value columns so it can filter out the metadata
###   for you.
### Observed Richness ###
# A simple count of the number of species found.
# Usually denoted by R or S
richness = function(abundance_table){
if (is.vector(abundance_table)){
abundance_table = matrix(abundance_table,1,length(abundance_table))
}
count = colSums(abundance_table,na.rm=TRUE)
sum(count>0)
}
### Estimated Richness ###
# We will likely go over this in lab.
# Basically, we need to fit some funcion to our rarefaction/collector's curve and find it's asymptote.
### Simpson's Diversity Index ###
# Usually denoted by lambda (or L)
# Equals the probability any two randomly chosen individuals in the population are the same.
# Therefore, actually a similarity index. To get diversity, D = 1/L
# Measure of both richness and evenness.
simpsons = function(abundance_table){
if (is.vector(abundance_table)){
abundance_table = matrix(abundance_table,1,length(abundance_table))
}
count = colSums(abundance_table,na.rm=TRUE)
p = count/sum(count)
sum(p^2)
}
### Shannon's Diversity Index (entropy) ###
# Usualy denoted by H'
# Does not have an easy mathematical explanation, but increases as diversity increases.
# Assumes infinite, well-mixed population.
# Also a measure of both richness and evenness.
shannons = function(abundance_table){
if (is.vector(abundance_table)){
abundance_table = matrix(abundance_table,1,length(abundance_table))
}
count = colSums(abundance_table,na.rm=TRUE)
count = count[count>0]
p = count/sum(count)
-sum(p*log(p^2))
}
### Chao1 ###
# Chao1 is a non-parametric estimator of richness. That means it makes no assumptions (infinite population,
# well mixed, specific model to fit and find an asymptote). It is observed richness, corrected
# with the number of singletons (species only seen once) and doubletons (species seen twice).
# There is actually some fancy statistics behind using singletons and doubletons as correctors.
chao1 = function(abundance_table){
if (is.vector(abundance_table)){
abundance_table = matrix(abundance_table,1,length(abundance_table))
}
count = colSums(abundance_table,na.rm=TRUE)
f1 = sum(count == 1)
f2 = sum(count == 2)
S = sum(count > 0)
return(S + f1*(f1-1)/(2*(f2+1)))
}
### Chao2 ###
# Similar to chao1 but uses incidence (pressence/absence) data instead of abundance.
# Running this on a single sample will return observed richness.
# instead of using doubleton and singleton species based on abundance, it uses species
# that were only found in one or two samples.
# This function will convert abundance data to incidence. If you have incidence data already,
# it can either be in 1s (pressence) and 0s (absence) or TRUE and FALSE.
chao2 = function(abundance_table){
abundance_table[abundance_table > 0] = 1
if (is.vector(abundance_table)){
abundance_table = matrix(abundance_table,1,length(abundance_table))
}
count = colSums(abundance_table,na.rm=TRUE)
q1 = sum(count == 1)
q2 = sum(count == 2)
S = sum(count > 0)
m = nrow(abundance_table)
return(S + (m-1)/m * q1*(q1-1)/(2*(q2+1)))
}
### Run all diversity and richness functions ###
# Specify which columns are the species counts if metadata is also included in the
# table. Optionally, specify a column to filter by (e.g., to run the diversity indices
# for each lake in a column name Lake use filter='Lake').
run_all_diversity = function(abundance_table,species_col=TRUE,filter_by=""){
if (filter_by != ""){
filter_unique = unique(abundance_table[[filter_by]])
num_unique = length(filter_unique)
}else{
filter_unique = TRUE
num_unique = 1
which_row = TRUE
}
richness_col = rep(0,num_unique)
shannons_col = rep(0,num_unique)
simpsons_col = rep(0,num_unique)
inv_simpsons_col = rep(0,num_unique)
chao1_col = rep(0,num_unique)
chao2_col = rep(0,num_unique)
for (u in 1:num_unique){
if (filter_by != ""){
which_row = abundance_table[[filter_by]]==filter_unique[u]
}
richness_col[u] = richness(abundance_table[which_row,species_col])
shannons_col[u] = shannons(abundance_table[which_row,species_col])
simpsons_col[u] = simpsons(abundance_table[which_row,species_col])
inv_simpsons_col[u] = 1/simpsons(abundance_table[which_row,species_col])
chao1_col[u] = chao1(abundance_table[which_row,species_col])
chao2_col[u] = chao2(abundance_table[which_row,species_col])
}
if (filter_by != ""){
output = data_frame(filter=filter_unique,
richness=richness_col,
shannons=shannons_col,
simpsons=simpsons_col,
inv_simpsons=inv_simpsons_col,
chao1=chao1_col,
chao2=chao2_col)
names(output)[1] = filter_by
}else{
output = data_frame(richness=richness_col,
shannons=shannons_col,
simpsons=simpsons_col,
inv_simpsons=inv_simpsons_col,
chao1=chao1_col,
chao2=chao2_col)
}
return(output)
}
### Rarefaction function ###
# Takes an abundance table and calculates a rarefaction curve for a specified function 'fun'.
# The default calculates a richness rarefaction, but any function that takes an abundance table works.
# Change the input 'species_col' to indicate which columns are the species counts if the table also
#     includes metadata.
# Change the input 'rand_combinations' to a non-zero integer to use only that number of random samples
#     instead of all possible. e.g., rand_combinations=100 would take the average of richness (or other fun)
#     for 100 different combinations of random samples (these can add up very quickly!). If the number
#     of samples in your data set is very smaple (~10 or so), you can set rand_combinations=Inf to use all
#     possible combinations.
# If you want to run the rarefaction multiple times filtered for each unique value in a specific column,
#     set the input 'filter_col' equal to the name of that column.
# Turn 'verbose' to FALSE if you don't want to see the output as it works.
rarefaction = function(abundance_table,
fun=richness,
species_col=T,
rand_combinations=100,
filter_col="",
verbose=TRUE){
if (filter_col != ""){
filter_unique = unique(abundance_table[[filter_col]])
filter_num = which(names(abundance_table)==filter_col)
num_unique = length(filter_unique)
n_sample = 0
for (u in filter_unique){
n_sample = max(n_sample,sum(abundance_table[[filter_col]]==u))
}
}else{
num_unique = 1
n_sample = nrow(abundance_table[,species_col])    # the number of samples in the dataset
}
output = rep(0,n_sample*num_unique)
output_95 = rep(0,n_sample*num_unique)
# loop over each unique element in the filter column if specified
for (u in 1:num_unique){
# filter the abundance table for the first element
if (filter_col != ""){
filter_abundance_table = filter_at(abundance_table,filter_num,all_vars(.==filter_unique[u]))
}else{
filter_abundance_table = abundance_table
}
filter_abundance_table = filter_abundance_table[,species_col]   # keep only the species count data
# loop from 1 to the number of samples
for (n in 1:n_sample){
n_combinations = choose(n_sample,n) # the total number of combinations of n samples
# check if the number of combinations is larger than specified
if (rand_combinations<n_combinations){
n_combinations = rand_combinations
sample_order = matrix(0,n,rand_combinations)
i = 1
while (i <= rand_combinations){ # loop over the number of combinations
sample_order[,i] = sample(n_sample,n) # random order of samples
for (j in 1:i){ # check to make sure the sample has not already been chosen
if (j != i){
if (all(sample_order[,i]-sample_order[,j] == 0)){
i = i-1
break
}
}
}
i = 1+i
}
}else{
sample_order = combn(n_sample,n) # find all possible combinations of n samples
}
temp_out = rep(0,n_combinations)
for (i in 1:n_combinations){
temp_sample = filter_abundance_table[sample_order[,i],] # use only chosen samples
temp_out[i] = fun(temp_sample) # calculate function
}
output[n + (u-1)*n_sample] = mean(temp_out)
output_95[n + (u-1)*n_sample] = 1.96*sd(temp_out)/sqrt(i) # calculate 95 confidence interval of the mean
if (verbose) print(paste(n+(u-1)*n_sample,'/',num_unique*n_sample,', Number of Samples:',n_combinations,', Value:',output[n],sep=""))
}
}
if (filter_col != ""){
return(tibble(n_samples=rep(1:n_sample,times=num_unique),
value=output,
conf_95=output_95,
filter=rep(filter_unique,each=n_sample)))
}else{
return(tibble(n_samples=1:n_sample,
value=output,
conf_95=output_95))
}
}
#####################################
# Biodiversity Measures Functions END#
#####################################
# run all diversity
run_all_diversity(amato_16s, species_col = 4: ncol(amato_16s)) # from 4th column to the end
seagrass_16s = read.table("Lab02/Seagrass_2015_otu_metadata_clean.txt",
header = TRUE,
sep = "\t")
view(seagrass_16s)
richness(seagrass_16s[,4:ncol(seagrass_16s)])
chao1(seagrass_16s[,4:ncol(seagrass_16s)])
richness(seagrass_16s[,4:ncol(seagrass_16s)])
shannons(seagrass_16s[,4:ncol(seagrass_16s)])
1/simpsons(seagrass_16s[,4:ncol(seagrass_16s)])
run_all_diversity(seagrass_16s, species_col = 4: ncol(seagrass_16s), filter_by = "sample_growth")
# Question 2: Richness, shannons, and 1/simpsons for each region
run_all_diversity(seagrass_16s, species_col = 4: ncol(seagrass_16s), filter_by = "region")
rarefaction(amato_16s)
amato_16s_richness = rarefaction(amato_16s, rand_combinations = 10)
amato_16s_collectors_curve = rarefaction(amato_16s, rand_combinations = 10)
ggplot(amato_16s_richness, aes(x=n_samples, y = value)) +
geom_point()
# Question 3: Rarefaction
rarefaction(seagrass_16s)
# Question 3: Rarefaction
rarefaction(seagrass_16s[,4:ncol(seagrass_16s)]])
# Question 3: Rarefaction
rarefaction(seagrass_16s[,4:ncol(seagrass_16s)])
rarefaction(seagrass_16s[,4:ncol(seagrass_16s)])
# Question 3: Rarefaction
head(rarefaction(seagrass_16s[,4:ncol(seagrass_16s)]))
# Question 3: Rarefaction
q3 <- rarefaction(seagrass_16s[,4:ncol(seagrass_16s)])
head(q3)
tail(q3)
q3_2 <- rarefaction(seagrass_16s[,4:ncol(seagrass_16s)])
head(q3_2)
tail(q3_2)
head(amato_16s_richness)
amato_16s_collectors_curve = rarefaction(amato_16s, rand_combinations = 10)
head(amato_16s_richness)
tail(amato_16s_richness)
# plotting
ggplot(amato_16s_richness, aes(x=n_samples, y = value)) +
geom_point()
tail(amato_16s_richness)
# go down
amato_16s_richness = rarefaction(amato_16s, rand_combinations = 10)
ggplot(amato_16s_richness, aes(x=n_samples, y = value)) +
geom_point()
data("cars")
cars_lm = lm(dist~speed, data = cars)
coef(cars_lm)
summary(cars_lm)
ggplot(cars, aes(x=speed, y=dist))+
geom_point()+
geom_smooth(method="lm", se=FALSE,formula = y~x)
ggplot(cars, aes(x= speed, y=dist))+
geom_point()+
geom_smooth(method="lm", se=FALSE,formula = y~log(x))
nls(dist~a*(1-exp(-b*speed)),
data=cars,
start = list(a=80,b=0.0001))
ggplot(amato_16s_richness, aes(x=n_sample, y=value))+
geom_point()
amato_16s_richness
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point()
amato_neg_exp =
nls(value~a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value, b=1)))
ggplot(amato_16s_collectors_curve, aes(x=n_samples, y = value)) +
geom_point()
ggplot(amato_16s_richness, aes(x=n_samples, y = value)) +
geom_point()
nls(value~a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value, b=1)))
amato_neg_exp =
nls(value~a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value, b=2))) #???missing
amato_neg_exp =
nls(value ~ a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value, b=10)))
ice_lake_data = filter(lake_data,Lake=="Ice Lake")
data(lake_temp_depth_lm)
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness, b=1)
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness, b=1)
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness, b=1)
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness), b=1)))
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness), b=10)))  #???missing
amato_neg_exp =
nls(value ~ a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value, b=10))) #???missing
amato_neg_exp =
nls(value ~ a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value), b=10))
amato_neg_exp =
nls(value ~ a*(1-exp(-b*n_samples)),
data=amato_16s_richness,
start = list(a=max(amato_16s_richness$value), b=1)) #???missing
amato_neg_exp
ggplot(amato_16s_richness, aes(x=n_samples, y=value))+
geom_point+
geom_smooth(method = "nls",
formula =y~a*(1-exp(-b*x)),
se=FALSE,
method.args= list(start=c(a=max(amato_16s_richness), b=1)))  #???missing
library(tidyverse)
lotr  <- read_csv("https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/lotr_tidy.csv")
guest <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/attend.csv")
email <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/emails.csv")
knitr::opts_chunk$set(error = TRUE, warning = FALSE)
lotr
(lotr_wide <- lotr %>%
pivot_wider(id_cols = c(-Race, -Words),
names_from = Race,
values_from = Words))
install.packages(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
lotr  <- read_csv("https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/lotr_tidy.csv")
guest <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/attend.csv")
email <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/emails.csv")
(lotr_wide <- lotr %>%
pivot_wider(id_cols = c(-Race, -Words),
names_from = Race,
values_from = Words))
lotr_wide %>%
pivot_longer(cols  = c(-Film, -Gender),
names_to  = "Race",
values_to = "Words")
devtools::install_github("tidyverse/tidyr")
install_github("tidyverse/tidyr")
library(tidyverse)
library(tidyr)
lotr  <- read_csv("https://raw.githubusercontent.com/jennybc/lotr-tidy/master/data/lotr_tidy.csv")
guest <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/attend.csv")
email <- read_csv("https://raw.githubusercontent.com/STAT545-UBC/Classroom/master/data/wedding/emails.csv")
(lotr_wide <- lotr %>%
pivot_wider(id_cols = c(-Race, -Words),
names_from = Race,
values_from = Words))
guest %>%
DT::datatable(rownames = FALSE)
(guest_long <- guest %>%
pivot_longer(cols      = FILL_THIS_IN,
names_to  = FILL_THIS_IN,
FILL_THIS_IN))
guest_long %>%
pivot_wider(id_cols     = c(party, name),
names_from  = c(event),
names_sep   = "_",
values_from = c(meal, attendance) ) # Tricky!
email %>%
separate_rows(FILL_THIS_IN, sep = FILL_THIS_IN)
